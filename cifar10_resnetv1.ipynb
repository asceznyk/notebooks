{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_resnetv1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydDhJoW9Ap_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.train import Checkpoint\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Input, LeakyReLU, ReLU, Flatten, Activation, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, Add, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgFRb0rNBEOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3_CEGabBOHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    lrate = 0.001\n",
        "    if epoch > 75:\n",
        "        lrate = 0.0005\n",
        "    if epoch > 100:\n",
        "        lrate = 0.0003\n",
        "    return lrate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlI_Pli_DLsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "num_classes = 10\n",
        "train_images = train_images/255\n",
        "test_images = test_images/255\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels,num_classes)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels,num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ii6vhsfBI42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNetv1:\n",
        "    def __init__(self, inputdims, outputdims, lr=0.001, regconst=0.00001, maxpool=False, epochs=125, \n",
        "                lrschedule=lr_schedule, batchsize=64):\n",
        "        self.inputdims = inputdims\n",
        "        self.outputdims = outputdims\n",
        "        self.lr = lr\n",
        "        self.regconst = regconst\n",
        "        self.filtermap = 32\n",
        "        self.lrschedule = lrschedule\n",
        "        self.optimizer = tf.keras.optimizers.Adam(lr=self.lr)\n",
        "        self.epochs = epochs\n",
        "        self.batchsize=batchsize\n",
        "        self.model = self.buildNet(maxpool)\n",
        "        self.datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "            rotation_range=15,\n",
        "            width_shift_range=0.1,\n",
        "            height_shift_range=0.1,\n",
        "            horizontal_flip=True,\n",
        "        )\n",
        "        self.model.summary()\n",
        "\n",
        "    def convBlock(self, x, filters=1, k=3):\n",
        "        x = Conv2D(filters*self.filtermap, (k, k), padding='same',\n",
        "                   kernel_regularizer=tf.keras.regularizers.l2(self.regconst))(x)\n",
        "        x = ReLU()(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def resBlock(self, i, filters=1):\n",
        "        x = self.convBlock(i, filters)\n",
        "        x = self.convBlock(i, filters)\n",
        "        x = Add()([x, i])\n",
        "        x = ReLU()(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def poolBlock(self, x, maxpool=False, k=2):\n",
        "        return AveragePooling2D((k, k))(x) if not maxpool else MaxPooling2D((k, k))(x)\n",
        "\n",
        "    def buildNet(self, maxpool):\n",
        "        image = Input(shape=(self.inputdims))\n",
        "\n",
        "        x = self.convBlock(image)\n",
        "        for i in range(2):\n",
        "            x = self.resBlock(x)\n",
        "\n",
        "        x = self.convBlock(x, 2)\n",
        "        x = self.poolBlock(x, maxpool)\n",
        "        for i in range(2):\n",
        "            x = self.resBlock(x, 2)\n",
        "\n",
        "        x = self.convBlock(x, 4)\n",
        "        x = self.poolBlock(x, maxpool)\n",
        "        for i in range(2):\n",
        "            x = self.resBlock(x, 4)\n",
        "\n",
        "        x = self.convBlock(x, 2)\n",
        "        x = self.poolBlock(x, maxpool)\n",
        "\n",
        "        x = Flatten()(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        probs = Dense(self.outputdims, activation='softmax')(x)\n",
        "\n",
        "        model = Model(image, probs)\n",
        "        model.compile(optimizer=self.optimizer,\n",
        "                      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def fit(self, xtrain, ytrain, xtest, ytest):\n",
        "        self.datagen.fit(xtrain)\n",
        "\n",
        "        history = self.model.fit(self.datagen.flow(xtrain, ytrain, batch_size=self.batchsize),\n",
        "                                    steps_per_epoch=train_images.shape[0] // self.batchsize, \n",
        "                                    epochs=self.epochs,\n",
        "                                    verbose=1, validation_data=(xtest, ytest), \n",
        "                                    callbacks=[LearningRateScheduler(self.lrschedule)])\n",
        "        \n",
        "        return history\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rUFVK0DBRsf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "908ac191-d727-491b-dc42-9ee4ab639848"
      },
      "source": [
        "resnetv1 = ResNetv1(train_images.shape[1:], num_classes, maxpool=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu (ReLU)                    (None, 32, 32, 32)   0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 32)   128         re_lu[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 32)   9248        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_2 (ReLU)                  (None, 32, 32, 32)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         re_lu_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 32)   0           batch_normalization_2[0][0]      \n",
            "                                                                 batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_3 (ReLU)                  (None, 32, 32, 32)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 32)   128         re_lu_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 32)   9248        batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_5 (ReLU)                  (None, 32, 32, 32)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 32)   128         re_lu_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 32)   0           batch_normalization_5[0][0]      \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_6 (ReLU)                  (None, 32, 32, 32)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 32)   128         re_lu_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 64)   18496       batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_7 (ReLU)                  (None, 32, 32, 64)   0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         re_lu_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   36928       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_9 (ReLU)                  (None, 16, 16, 64)   0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 64)   256         re_lu_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 16, 16, 64)   0           batch_normalization_9[0][0]      \n",
            "                                                                 max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_10 (ReLU)                 (None, 16, 16, 64)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 64)   256         re_lu_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 64)   36928       batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_12 (ReLU)                 (None, 16, 16, 64)   0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   256         re_lu_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "                                                                 batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_13 (ReLU)                 (None, 16, 16, 64)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 64)   256         re_lu_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 128)  73856       batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_14 (ReLU)                 (None, 16, 16, 128)  0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 128)  512         re_lu_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 128)    0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 8, 8, 128)    147584      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_16 (ReLU)                 (None, 8, 8, 128)    0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 128)    512         re_lu_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 8, 8, 128)    0           batch_normalization_16[0][0]     \n",
            "                                                                 max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_17 (ReLU)                 (None, 8, 8, 128)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 128)    512         re_lu_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 128)    147584      batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_19 (ReLU)                 (None, 8, 8, 128)    0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 128)    512         re_lu_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 8, 8, 128)    0           batch_normalization_19[0][0]     \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_20 (ReLU)                 (None, 8, 8, 128)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 8, 8, 128)    512         re_lu_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 64)     73792       batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_21 (ReLU)                 (None, 8, 8, 64)     0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8, 8, 64)     256         re_lu_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 64)     0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1024)         0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           10250       dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 569,546\n",
            "Trainable params: 567,178\n",
            "Non-trainable params: 2,368\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4-V8m1Sw1mj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "26ece604-326e-4701-9f91-0647e19a6c0c"
      },
      "source": [
        "resnetv1.fit(train_images, train_labels, test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 1.7341 - accuracy: 0.4423 - val_loss: 1.5806 - val_accuracy: 0.5028 - lr: 0.0010\n",
            "Epoch 2/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 1.1956 - accuracy: 0.6016 - val_loss: 1.1651 - val_accuracy: 0.6290 - lr: 0.0010\n",
            "Epoch 3/125\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.9303 - accuracy: 0.6784 - val_loss: 0.9217 - val_accuracy: 0.6983 - lr: 0.0010\n",
            "Epoch 4/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.7902 - accuracy: 0.7295 - val_loss: 0.8440 - val_accuracy: 0.7179 - lr: 0.0010\n",
            "Epoch 5/125\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.7132 - accuracy: 0.7579 - val_loss: 0.7576 - val_accuracy: 0.7505 - lr: 0.0010\n",
            "Epoch 6/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6553 - accuracy: 0.7780 - val_loss: 0.7379 - val_accuracy: 0.7573 - lr: 0.0010\n",
            "Epoch 7/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6011 - accuracy: 0.7998 - val_loss: 0.6616 - val_accuracy: 0.7872 - lr: 0.0010\n",
            "Epoch 8/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5625 - accuracy: 0.8134 - val_loss: 0.6908 - val_accuracy: 0.7804 - lr: 0.0010\n",
            "Epoch 9/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5275 - accuracy: 0.8271 - val_loss: 0.6140 - val_accuracy: 0.8153 - lr: 0.0010\n",
            "Epoch 10/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4985 - accuracy: 0.8374 - val_loss: 0.5625 - val_accuracy: 0.8239 - lr: 0.0010\n",
            "Epoch 11/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4766 - accuracy: 0.8459 - val_loss: 0.5522 - val_accuracy: 0.8286 - lr: 0.0010\n",
            "Epoch 12/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4576 - accuracy: 0.8546 - val_loss: 0.5765 - val_accuracy: 0.8313 - lr: 0.0010\n",
            "Epoch 13/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4397 - accuracy: 0.8618 - val_loss: 0.4730 - val_accuracy: 0.8574 - lr: 0.0010\n",
            "Epoch 14/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4204 - accuracy: 0.8686 - val_loss: 0.5011 - val_accuracy: 0.8487 - lr: 0.0010\n",
            "Epoch 15/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4082 - accuracy: 0.8725 - val_loss: 0.5646 - val_accuracy: 0.8291 - lr: 0.0010\n",
            "Epoch 16/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3985 - accuracy: 0.8790 - val_loss: 0.5210 - val_accuracy: 0.8506 - lr: 0.0010\n",
            "Epoch 17/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3891 - accuracy: 0.8851 - val_loss: 0.5328 - val_accuracy: 0.8491 - lr: 0.0010\n",
            "Epoch 18/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3783 - accuracy: 0.8867 - val_loss: 0.4616 - val_accuracy: 0.8650 - lr: 0.0010\n",
            "Epoch 19/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3667 - accuracy: 0.8927 - val_loss: 0.4905 - val_accuracy: 0.8589 - lr: 0.0010\n",
            "Epoch 20/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3654 - accuracy: 0.8926 - val_loss: 0.4610 - val_accuracy: 0.8689 - lr: 0.0010\n",
            "Epoch 21/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3570 - accuracy: 0.8979 - val_loss: 0.4863 - val_accuracy: 0.8639 - lr: 0.0010\n",
            "Epoch 22/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3496 - accuracy: 0.9009 - val_loss: 0.4628 - val_accuracy: 0.8762 - lr: 0.0010\n",
            "Epoch 23/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3457 - accuracy: 0.9026 - val_loss: 0.4931 - val_accuracy: 0.8671 - lr: 0.0010\n",
            "Epoch 24/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3398 - accuracy: 0.9041 - val_loss: 0.5070 - val_accuracy: 0.8615 - lr: 0.0010\n",
            "Epoch 25/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3338 - accuracy: 0.9090 - val_loss: 0.4691 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 26/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3328 - accuracy: 0.9095 - val_loss: 0.4388 - val_accuracy: 0.8856 - lr: 0.0010\n",
            "Epoch 27/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3250 - accuracy: 0.9121 - val_loss: 0.4576 - val_accuracy: 0.8781 - lr: 0.0010\n",
            "Epoch 28/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3237 - accuracy: 0.9142 - val_loss: 0.4622 - val_accuracy: 0.8774 - lr: 0.0010\n",
            "Epoch 29/125\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.3186 - accuracy: 0.9171 - val_loss: 0.4446 - val_accuracy: 0.8866 - lr: 0.0010\n",
            "Epoch 30/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3131 - accuracy: 0.9193 - val_loss: 0.4257 - val_accuracy: 0.8898 - lr: 0.0010\n",
            "Epoch 31/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3158 - accuracy: 0.9185 - val_loss: 0.4521 - val_accuracy: 0.8830 - lr: 0.0010\n",
            "Epoch 32/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3082 - accuracy: 0.9214 - val_loss: 0.4830 - val_accuracy: 0.8786 - lr: 0.0010\n",
            "Epoch 33/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3038 - accuracy: 0.9238 - val_loss: 0.5151 - val_accuracy: 0.8716 - lr: 0.0010\n",
            "Epoch 34/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3036 - accuracy: 0.9241 - val_loss: 0.5114 - val_accuracy: 0.8758 - lr: 0.0010\n",
            "Epoch 35/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3057 - accuracy: 0.9239 - val_loss: 0.4626 - val_accuracy: 0.8818 - lr: 0.0010\n",
            "Epoch 36/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3020 - accuracy: 0.9261 - val_loss: 0.5552 - val_accuracy: 0.8617 - lr: 0.0010\n",
            "Epoch 37/125\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.2956 - accuracy: 0.9283 - val_loss: 0.4425 - val_accuracy: 0.8921 - lr: 0.0010\n",
            "Epoch 38/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3013 - accuracy: 0.9271 - val_loss: 0.4500 - val_accuracy: 0.8870 - lr: 0.0010\n",
            "Epoch 39/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2926 - accuracy: 0.9316 - val_loss: 0.5412 - val_accuracy: 0.8696 - lr: 0.0010\n",
            "Epoch 40/125\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.2978 - accuracy: 0.9294 - val_loss: 0.4970 - val_accuracy: 0.8820 - lr: 0.0010\n",
            "Epoch 41/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.2963 - accuracy: 0.9302 - val_loss: 0.4446 - val_accuracy: 0.8912 - lr: 0.0010\n",
            "Epoch 42/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.2925 - accuracy: 0.9327 - val_loss: 0.4542 - val_accuracy: 0.8952 - lr: 0.0010\n",
            "Epoch 43/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.2916 - accuracy: 0.9336 - val_loss: 0.5741 - val_accuracy: 0.8658 - lr: 0.0010\n",
            "Epoch 44/125\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.2876 - accuracy: 0.9350 - val_loss: 0.4933 - val_accuracy: 0.8829 - lr: 0.0010\n",
            "Epoch 45/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2881 - accuracy: 0.9357 - val_loss: 0.4748 - val_accuracy: 0.8898 - lr: 0.0010\n",
            "Epoch 46/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2890 - accuracy: 0.9366 - val_loss: 0.5068 - val_accuracy: 0.8802 - lr: 0.0010\n",
            "Epoch 47/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2847 - accuracy: 0.9376 - val_loss: 0.5169 - val_accuracy: 0.8833 - lr: 0.0010\n",
            "Epoch 48/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2859 - accuracy: 0.9384 - val_loss: 0.4583 - val_accuracy: 0.8949 - lr: 0.0010\n",
            "Epoch 49/125\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.2837 - accuracy: 0.9375 - val_loss: 0.4776 - val_accuracy: 0.8873 - lr: 0.0010\n",
            "Epoch 50/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2867 - accuracy: 0.9385 - val_loss: 0.4981 - val_accuracy: 0.8891 - lr: 0.0010\n",
            "Epoch 51/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2841 - accuracy: 0.9385 - val_loss: 0.4397 - val_accuracy: 0.9012 - lr: 0.0010\n",
            "Epoch 52/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2817 - accuracy: 0.9409 - val_loss: 0.5271 - val_accuracy: 0.8806 - lr: 0.0010\n",
            "Epoch 53/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2838 - accuracy: 0.9389 - val_loss: 0.4766 - val_accuracy: 0.8949 - lr: 0.0010\n",
            "Epoch 54/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2777 - accuracy: 0.9422 - val_loss: 0.5338 - val_accuracy: 0.8807 - lr: 0.0010\n",
            "Epoch 55/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2809 - accuracy: 0.9410 - val_loss: 0.5451 - val_accuracy: 0.8786 - lr: 0.0010\n",
            "Epoch 56/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2767 - accuracy: 0.9420 - val_loss: 0.4480 - val_accuracy: 0.9021 - lr: 0.0010\n",
            "Epoch 57/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2785 - accuracy: 0.9436 - val_loss: 0.5091 - val_accuracy: 0.8835 - lr: 0.0010\n",
            "Epoch 58/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2773 - accuracy: 0.9438 - val_loss: 0.5424 - val_accuracy: 0.8797 - lr: 0.0010\n",
            "Epoch 59/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2781 - accuracy: 0.9426 - val_loss: 0.5654 - val_accuracy: 0.8694 - lr: 0.0010\n",
            "Epoch 60/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2721 - accuracy: 0.9461 - val_loss: 0.5624 - val_accuracy: 0.8765 - lr: 0.0010\n",
            "Epoch 61/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2746 - accuracy: 0.9449 - val_loss: 0.5367 - val_accuracy: 0.8887 - lr: 0.0010\n",
            "Epoch 62/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2749 - accuracy: 0.9456 - val_loss: 0.5097 - val_accuracy: 0.8924 - lr: 0.0010\n",
            "Epoch 63/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2710 - accuracy: 0.9464 - val_loss: 0.4969 - val_accuracy: 0.8904 - lr: 0.0010\n",
            "Epoch 64/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2724 - accuracy: 0.9458 - val_loss: 0.5060 - val_accuracy: 0.8887 - lr: 0.0010\n",
            "Epoch 65/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2724 - accuracy: 0.9472 - val_loss: 0.4624 - val_accuracy: 0.9010 - lr: 0.0010\n",
            "Epoch 66/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2686 - accuracy: 0.9489 - val_loss: 0.5242 - val_accuracy: 0.8854 - lr: 0.0010\n",
            "Epoch 67/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2697 - accuracy: 0.9482 - val_loss: 0.5113 - val_accuracy: 0.8932 - lr: 0.0010\n",
            "Epoch 68/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2724 - accuracy: 0.9467 - val_loss: 0.5114 - val_accuracy: 0.8861 - lr: 0.0010\n",
            "Epoch 69/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2707 - accuracy: 0.9476 - val_loss: 0.4738 - val_accuracy: 0.9020 - lr: 0.0010\n",
            "Epoch 70/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2691 - accuracy: 0.9495 - val_loss: 0.4870 - val_accuracy: 0.8949 - lr: 0.0010\n",
            "Epoch 71/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2700 - accuracy: 0.9495 - val_loss: 0.4774 - val_accuracy: 0.8995 - lr: 0.0010\n",
            "Epoch 72/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2639 - accuracy: 0.9513 - val_loss: 0.5295 - val_accuracy: 0.8844 - lr: 0.0010\n",
            "Epoch 73/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2713 - accuracy: 0.9485 - val_loss: 0.4643 - val_accuracy: 0.9030 - lr: 0.0010\n",
            "Epoch 74/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2703 - accuracy: 0.9496 - val_loss: 0.4527 - val_accuracy: 0.9013 - lr: 0.0010\n",
            "Epoch 75/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2646 - accuracy: 0.9512 - val_loss: 0.5005 - val_accuracy: 0.8932 - lr: 0.0010\n",
            "Epoch 76/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2664 - accuracy: 0.9518 - val_loss: 0.4929 - val_accuracy: 0.8950 - lr: 0.0010\n",
            "Epoch 77/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2375 - accuracy: 0.9614 - val_loss: 0.4864 - val_accuracy: 0.9035 - lr: 5.0000e-04\n",
            "Epoch 78/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.2242 - accuracy: 0.9649 - val_loss: 0.4590 - val_accuracy: 0.9104 - lr: 5.0000e-04\n",
            "Epoch 79/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2215 - accuracy: 0.9664 - val_loss: 0.4579 - val_accuracy: 0.9119 - lr: 5.0000e-04\n",
            "Epoch 80/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2137 - accuracy: 0.9682 - val_loss: 0.4830 - val_accuracy: 0.9085 - lr: 5.0000e-04\n",
            "Epoch 81/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.2139 - accuracy: 0.9681 - val_loss: 0.4692 - val_accuracy: 0.9106 - lr: 5.0000e-04\n",
            "Epoch 82/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.2074 - accuracy: 0.9696 - val_loss: 0.4723 - val_accuracy: 0.9090 - lr: 5.0000e-04\n",
            "Epoch 83/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.2035 - accuracy: 0.9711 - val_loss: 0.4600 - val_accuracy: 0.9108 - lr: 5.0000e-04\n",
            "Epoch 84/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.2100 - accuracy: 0.9685 - val_loss: 0.4578 - val_accuracy: 0.9137 - lr: 5.0000e-04\n",
            "Epoch 85/125\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.2027 - accuracy: 0.9700 - val_loss: 0.4808 - val_accuracy: 0.9100 - lr: 5.0000e-04\n",
            "Epoch 86/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2046 - accuracy: 0.9693 - val_loss: 0.4990 - val_accuracy: 0.9012 - lr: 5.0000e-04\n",
            "Epoch 87/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2029 - accuracy: 0.9706 - val_loss: 0.4945 - val_accuracy: 0.9086 - lr: 5.0000e-04\n",
            "Epoch 88/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1940 - accuracy: 0.9732 - val_loss: 0.4826 - val_accuracy: 0.9113 - lr: 5.0000e-04\n",
            "Epoch 89/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.2029 - accuracy: 0.9702 - val_loss: 0.5012 - val_accuracy: 0.9062 - lr: 5.0000e-04\n",
            "Epoch 90/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1943 - accuracy: 0.9728 - val_loss: 0.4925 - val_accuracy: 0.9056 - lr: 5.0000e-04\n",
            "Epoch 91/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1927 - accuracy: 0.9735 - val_loss: 0.4921 - val_accuracy: 0.9080 - lr: 5.0000e-04\n",
            "Epoch 92/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1930 - accuracy: 0.9733 - val_loss: 0.4902 - val_accuracy: 0.9097 - lr: 5.0000e-04\n",
            "Epoch 93/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1923 - accuracy: 0.9721 - val_loss: 0.4854 - val_accuracy: 0.9045 - lr: 5.0000e-04\n",
            "Epoch 94/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1904 - accuracy: 0.9732 - val_loss: 0.4876 - val_accuracy: 0.9102 - lr: 5.0000e-04\n",
            "Epoch 95/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1929 - accuracy: 0.9721 - val_loss: 0.4737 - val_accuracy: 0.9111 - lr: 5.0000e-04\n",
            "Epoch 96/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1928 - accuracy: 0.9716 - val_loss: 0.4879 - val_accuracy: 0.9082 - lr: 5.0000e-04\n",
            "Epoch 97/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1865 - accuracy: 0.9744 - val_loss: 0.5317 - val_accuracy: 0.9016 - lr: 5.0000e-04\n",
            "Epoch 98/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1886 - accuracy: 0.9729 - val_loss: 0.4823 - val_accuracy: 0.9066 - lr: 5.0000e-04\n",
            "Epoch 99/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1843 - accuracy: 0.9745 - val_loss: 0.5040 - val_accuracy: 0.9081 - lr: 5.0000e-04\n",
            "Epoch 100/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1870 - accuracy: 0.9738 - val_loss: 0.4820 - val_accuracy: 0.9103 - lr: 5.0000e-04\n",
            "Epoch 101/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1882 - accuracy: 0.9721 - val_loss: 0.5023 - val_accuracy: 0.9077 - lr: 5.0000e-04\n",
            "Epoch 102/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1729 - accuracy: 0.9779 - val_loss: 0.4792 - val_accuracy: 0.9141 - lr: 3.0000e-04\n",
            "Epoch 103/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1680 - accuracy: 0.9793 - val_loss: 0.4705 - val_accuracy: 0.9153 - lr: 3.0000e-04\n",
            "Epoch 104/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1659 - accuracy: 0.9794 - val_loss: 0.5011 - val_accuracy: 0.9108 - lr: 3.0000e-04\n",
            "Epoch 105/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1672 - accuracy: 0.9799 - val_loss: 0.4913 - val_accuracy: 0.9096 - lr: 3.0000e-04\n",
            "Epoch 106/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1620 - accuracy: 0.9805 - val_loss: 0.4826 - val_accuracy: 0.9143 - lr: 3.0000e-04\n",
            "Epoch 107/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1608 - accuracy: 0.9815 - val_loss: 0.4914 - val_accuracy: 0.9117 - lr: 3.0000e-04\n",
            "Epoch 108/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1593 - accuracy: 0.9810 - val_loss: 0.4798 - val_accuracy: 0.9124 - lr: 3.0000e-04\n",
            "Epoch 109/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1544 - accuracy: 0.9836 - val_loss: 0.4847 - val_accuracy: 0.9130 - lr: 3.0000e-04\n",
            "Epoch 110/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1584 - accuracy: 0.9815 - val_loss: 0.5013 - val_accuracy: 0.9107 - lr: 3.0000e-04\n",
            "Epoch 111/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1537 - accuracy: 0.9831 - val_loss: 0.4874 - val_accuracy: 0.9129 - lr: 3.0000e-04\n",
            "Epoch 112/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1575 - accuracy: 0.9825 - val_loss: 0.4971 - val_accuracy: 0.9126 - lr: 3.0000e-04\n",
            "Epoch 113/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1555 - accuracy: 0.9819 - val_loss: 0.4942 - val_accuracy: 0.9140 - lr: 3.0000e-04\n",
            "Epoch 114/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1547 - accuracy: 0.9824 - val_loss: 0.5053 - val_accuracy: 0.9114 - lr: 3.0000e-04\n",
            "Epoch 115/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.1552 - accuracy: 0.9819 - val_loss: 0.5526 - val_accuracy: 0.9056 - lr: 3.0000e-04\n",
            "Epoch 116/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.1547 - accuracy: 0.9824 - val_loss: 0.5443 - val_accuracy: 0.9040 - lr: 3.0000e-04\n",
            "Epoch 117/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1512 - accuracy: 0.9830 - val_loss: 0.4943 - val_accuracy: 0.9156 - lr: 3.0000e-04\n",
            "Epoch 118/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1518 - accuracy: 0.9829 - val_loss: 0.4882 - val_accuracy: 0.9132 - lr: 3.0000e-04\n",
            "Epoch 119/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1490 - accuracy: 0.9831 - val_loss: 0.4731 - val_accuracy: 0.9155 - lr: 3.0000e-04\n",
            "Epoch 120/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1486 - accuracy: 0.9833 - val_loss: 0.4867 - val_accuracy: 0.9173 - lr: 3.0000e-04\n",
            "Epoch 121/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1491 - accuracy: 0.9825 - val_loss: 0.4754 - val_accuracy: 0.9159 - lr: 3.0000e-04\n",
            "Epoch 122/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1527 - accuracy: 0.9820 - val_loss: 0.4955 - val_accuracy: 0.9126 - lr: 3.0000e-04\n",
            "Epoch 123/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1467 - accuracy: 0.9836 - val_loss: 0.5244 - val_accuracy: 0.9116 - lr: 3.0000e-04\n",
            "Epoch 124/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1456 - accuracy: 0.9835 - val_loss: 0.5237 - val_accuracy: 0.9067 - lr: 3.0000e-04\n",
            "Epoch 125/125\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1465 - accuracy: 0.9831 - val_loss: 0.5083 - val_accuracy: 0.9111 - lr: 3.0000e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f28eefb8240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z15jBlbz9ec5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08d850cf-7cb6-494c-dc17-621d3c228a9b"
      },
      "source": [
        "test_loss, test_acc = resnetv1.model.evaluate(test_images,  test_labels, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 0.5083 - accuracy: 0.9111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH0QKrJgBbJZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "7b887cb0-e9b4-4699-fa21-e1e2d7923ad0"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-f4d76527f34b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lower right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDlZ8klfDS0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}